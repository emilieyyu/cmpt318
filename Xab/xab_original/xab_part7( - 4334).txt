Frequency-Based Identification of Correct Translation Equivalents (FITE) Obtained Through Transformation Rules
ARI PIRKOLA, JARMO TOIVONEN, HEIKKI KESKUSTALO, ¨ and KALERVO JARVELIN University of Tampere

2

We devised a novel statistical technique for the identification of the translation equivalents of source words obtained by transformation rule based translation (TRT). The effectiveness of the technique called frequency-based identification of translation equivalents (FITE) was tested using biological and medical cross-lingual spelling variants and out-of-vocabulary (OOV) words in Spanish-English and Finnish-English TRT. The results showed that, depending on the source language and frequency corpus, FITE-TRT (the identification of translation equivalents from TRT's translation set by means of the FITE technique) may achieve high translation recall. In the case of the Web as the frequency corpus, translation recall was 89.2%­91.0% for Spanish-English FITE-TRT. For both language pairs FITE-TRT achieved high translation precision: 95.0%­98.8%. The technique also reliably identified native source language words: source words that cannot be correctly translated by TRT. Dictionary-based CLIR augmented with FITE-TRT performed substantially better than basic dictionary-based CLIR where OOV keys were kept intact. FITE-TRT with Web document frequencies was the best technique among several fuzzy translation/matching approaches tested in cross-language retrieval experiments. We also discuss the application of FITE-TRT in the automatic construction of multilingual dictionaries. Categories and Subject Descriptors: H.3.3 [Information Storage and Retrieval]: Information Search and Retrieval General Terms: Algorithms, Experimentation, Languages, Performance Additional Key Words and Phrases: Cross-language information retrieval, fuzzy matching, OOV words, transformation rules, transliteration ACM Reference Format: Pirkola, A., Toivonen, J., Keskustalo, H., and Kalervo, J. Frequency-based identification of correct translation equivalents (FITE) obtained through transformation rules. ACM Trans. Inform. Syst. 26, 1, Article 2 (November 2007), 25 pages. DOI = 10.1145/1292591.1292593 http://doi.acm.org/ 10.1145/1292591.1292593 This study was financed by the Finnish Academy projects no. 204978, no. 1209960 (Multilingual and Task-Based Information Retrieval), and no. 1206568 (NLP-Based Information Retrieval Systems for the Biological Literature). Authors' addresses: Department of Information Studies, 33014 University of Tampere, Finland; email: pirkola@cc.jyu.fi; {jarmo.toivonen, heikki.keskustalo, kalervo.jarvelin}@uta.fi. Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or direct commercial advantage and that copies show this notice on the first page or initial screen of a display along with the full citation. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, to republish, to post on servers, to redistribute to lists, or to use any component of this work in other works requires prior specific permission and/or a fee. Permissions may be requested from Publications Dept., ACM, Inc., 2 Penn Plaza, Suite 701, New York, NY 10121-0701, USA, fax +1 (212) 869-0481, or permissions@acm.org. C 2007 ACM 1046-8188/2007/11-ART2 $5.00 DOI 10.1145/1292591.1292593 http://doi.acm.org/ 10.1145/1292591.1292593
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

2:2

·

A. Pirkola et al.

1. INTRODUCTION Out-of-vocabulary (OOV) words constitute a major problem in cross-language information retrieval (CLIR) and machine translation (MT). In those cases where equivalent terms in different languages are etymologically related technical terms (cross-lingual spelling variants--as German konstruktion and English construction) it is possible to use a transliteration type of translation to recognize the target language equivalents of the source language words. In Pirkola et al. [2003] we generated automatically large collections of character correspondences in several language pairs for the translation of cross-lingual spelling variants. Equivalent term pairs in two languages were first extracted automatically from translation dictionaries, and then regular character correspondences between the words in the two languages were identified using an edit distance measure. Large sets of transformation rules augmented with statistical information were generated for automatic translation of spelling variants. We call the translation technique based on the generated rules transformation rule based translation (TRT). TRT is similar to transliteration except that no phonetic elements are involved in it. The term fuzzy translation is used in connection with TRT. It refers to the fact that TRT often gives many possible equivalents for a source word, not one equivalent or several alternatives like regular translation. In Toivonen et al. [2005] we showed that high translation recall--the proportion of source words for which TRT yields equivalents among all source words--may be achieved when most of the rules available for a source word are used in TRT. However, high translation recall is associated with low translation precision (the proportion of equivalents among all word forms yielded by TRT). In other words, the translation set containing the target language word forms often includes the correct translation equivalent of a source word and a large number of other word forms. It is obvious that a technique where words not found in a dictionary are translated by transformation rules would be useful in many information systems where automatic translation is part of the system. However, in many cases the TRT technique may be useless if it just indicates a set of possible translations for a source word but is not able to indicate the one correct equivalent, which was the case in Pirkola et al. [2003] as well as in Toivonen et al. [2005]. In the present research we attack this problem, moving TRT from fuzzy translation towards dictionary-like translation, where for each source word either one translation equivalent is indicated or the source word is indicated not to be translatable by means of TRT. For this we developed a novel statistical equivalent identification technique called frequency-based identification of translation equivalents (FITE). The identification of equivalents is based on regular frequency patterns associated with the target word forms obtained by TRT. In this paper we also present a novel feature of TRT: translation through indirect translation routes. If a direct translation from a source language into a target language fails to find an equivalent, the source word is retranslated into a target language through intermediate (pivot) languages. As in the case
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

Frequency-Based Identification of Correct Translation Equivalents (FITE)

·

2:3

of direct translation the equivalents are identified from TRT's translation set by means of the novel FITE technique. Transitive translation through a pivot language is a well-known technique in CLIR, used to address the problem of limited availability of translation resources [Ballesteros 2000; Gollins and Sanderson 2001; Lehtokangas et al. 2004]. Indirect translation could be used in TRT in cases where direct translation is not possible due to the lack of translation resources (transformation rules). In this study, however, we investigate whether indirect translation improves FITE-TRT effectiveness. It may compensate the failures of direct translation and thereby increase translation recall. We explore the effectiveness of FITE in Spanish-English and FinnishEnglish TRT. German and French serve as intermediate languages for both language pairs. As test words we use terms in the domains of biology and medicine. The terms were selected from texts and real information requests of biomedical researchers. FITE-TRT is also applied as part of an actual CLIR system. The effectiveness of dictionary-based CLIR augmented with FITE-TRT is compared to the effectiveness of dictionary-based CLIR augmented with plain TRT and skipgram [Keskustalo et al. 2003] OOV word methods. We also run dictionary-translationonly (no OOV word technique is applied) and monolingual English queries as baselines. In Pirkola et al. [2006] we presented the main features of FITE-TRT and the first results on FITE-TRT effectiveness and the effectiveness of CLIR augmented with FITE-TRT. In this article we describe the FITE-TRT technique in more detail, present the find-equivalent algorithm, and extend the first study by using large word frequency lists mined from the Web as FITE-TRT's frequency source, and by comparing FITE-TRT to other OOV word methods in cross-language retrieval experiments. The novel FITE-TRT technique is fundamentally different from other OOV word methods/systems presented in the literature. For instance, Cheng et al. [2004] and Zhang and Vines [2004] both developed a Web-based translation method for Chinese-English OOV words, where the OOV words were extracted from bilingual Chinese-English texts found in Chinese Web pages using word co-occurrence statistics and syntactic structures. Meng et al. [2000] employed a TRT type rule-based approach to the OOV word problem. Phonetic mappings were derived from English and Chinese (Mandarin) pronunciation rules for English-Chinese spoken document retrieval. The researchers also considered Chinese name variation. An English proper name may have several character sequence variants and pronunciations in Chinese. To combat this problem the transliteration approach should involve approximate matches between the English and Chinese pronunciations. Fujii and Ishikawa [2001] used characterbased rules to establish mapping between English characters and romanized Japanese katakana characters. They also utilized probabilistic character-based language models, which can be seen as a variation of fuzzy matching. The technique is different from FITE-TRT but bears some resemblance to the fuzzy translation reported in Pirkola et al. [2003], however focusing on languages with different orthographies, thus having a different focus. The skipgram fuzzy
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

2:4

·

A. Pirkola et al.

matching approach to OOV words by Keskustalo et al. [2003] is discussed in Section 5.2.1. The rest of this article is organized as follows. Section 2 presents the TRT technique, its background research, the transformation rule collections, and the dictionary data that was used in the rule generation. In Section 3 we define the terms cross-lingual spelling variant and native word, and present the research problems and evaluation measures used in the experiments. The novel FITE technique is described in Section 4. Section 5 presents the methods and data used in the experiments and the findings. Section 6 contains discussion and conclusions. 2. TRT, TRANSFORMATION RULES AND BACKGROUND RESEARCH The idea of TRT and the automatic method to generate transformation rules is described in Pirkola et al. [2003]. A transformation rule contains source and target language characters that are transformed, and their context characters. In addition, there are two important numerical factors associated with a rule: frequency and confidence factor, which may be used as thresholds to select the most common and reliable rules for TRT. Frequency refers to the number of the occurrences of the rule in the dictionary data that was used for the rule generation. Confidence factor (CF) is defined as the frequency of a rule divided by the number of source words where the source substring of the rule occurs. Below we present an example of a German-English rule: ekt ect middle 191 214 89.25 The rule is read as follows: the letter k, prior to t and after e, is transformed into the letter c in the middle of words, with the confidence factor being 89.25% (100% * 191/214). Examples of target word forms obtained in TRT are shown in Sections 4.2 and 4.3. In Pirkola et al. [2003] we studied TRT in combination with fuzzy matching-- digram and trigram matching. We investigated five source languages, with English being a target language for all the source languages. The results showed that for Finnish, German and Spanish the combined technique performed better than digrams and trigrams alone. For French and Swedish performance changes were slight. In Toivonen et al. [2005] we studied how effective TRT is without fuzzy matching. We found that translation recall was high when low frequency and confidence factor were used as thresholds to select the rules for TRT. However, at low confidence factor and frequency levels, translation precision was low. The FITE-TRT technique addresses this problem and, as we will show in this article, it achieves both high recall and precision. The transformation rules used in TRT in this study were generated using the rule generation method based on the use of dictionary data described in Pirkola et al. [2003]. The dictionary data consisted of a multilingual medical dictionary by Andre Fairchild (http://members.interfold.com/translator/) for the language pairs of Spanish-English, Spanish-German, Spanish-French, German-English, and French-English. For Finnish-English the data for rule generation was obtained by translating (1) a list of Finnish medical terms into English using a
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

Frequency-Based Identification of Correct Translation Equivalents (FITE)
Table I. Dictionary and Transformation Rule Collection Statistics Dictionary/Rule collection Spanish-English Spanish-German Spanish-French German-English French-English # Entries 19029 14252 15183 18917 17089 Avg. # translations 1.58 1.70 1.66 1.70 1.91 # Rules 8800 5412 9724 8609 9873

·

2:5

# Rules CF  4.0%, Freq. 2 1295 984 1430 1219 1170

medical dictionary by Kielikone Inc., and (2) a list of Finnish terms in various domains into English using Kielikone's general-purpose dictionary. Thus, for Finnish-English we constructed two collections. The second collection was constructed because the first collection missed many important rules. Table I shows the number of entries and the average number of translations per an entry for each dictionary used in the rule generation (columns 2 and 3). Table I also shows the total number of rules in the generated rule collections as well the number of rules at or above the thresholds of CF = 4.0% and frequency = 2 applied in this study (columns 4 and 5). We applied the confidence factor and frequency thresholds because TRT may give very large translation sets, and at the present stage of development the TRT program is not efficient enough to process very large word sets. Due to the efficiency issues, we also applied a limit of 40 word forms: if there were more than 40 word forms in a translation set of an intermediate language the source word was retranslated by TRT with a confidence factor of 10.0% and frequency of 10, to yield a smaller translation set. As can be seen in Table I, each rule collection contains a high number of rules, which suggests that the rule generation method effectively captured spelling variation between the language pairs. 3. RESEARCH PROBLEMS AND EVALUATION MEASURES We distinguish between two kinds of words in a language with respect to the words in another language: cross-lingual spelling variants and native words. Cross-lingual spelling variants are etymologically related words and therefore similar in the two languages, differing only slightly in spelling. A native word and its target language equivalent are not related to each other morphologically even if they share the same meaning. The words have different origins and etymologies in the history of the respective languages. The words do not have morphological or phonetic resemblance--or if there is some, it is purely accidental. As examples, consider the English words computer and chemotherapy and their Finnish equivalents tietokone and kemoterapia. The first pair computertietokone do not have morphological or phonetic resemblance, computer originating from Latin (computare, to calculate) and tietokone being a compound of knowledge and machine. The Finnish words tieto and kone are old words in the language. In the second pair chemotherapy-kemoterapia both words originate from Greek (chemeia + therapeia) and, albeit having been modified to fit
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

2:6

·

A. Pirkola et al.

the style of their present languages, still have not lost their morphological or phonetic resemblance. TRT is intended to translate spelling variants and FITE is intended to identify the translation equivalents of spelling variants and to indicate the native source language words--the source words that cannot be correctly translated by TRT. Using test word sets containing both types of words, we examine the following research questions: r In the case of spelling variants, how to effectively identify the correct equivalent of a source word among the many word forms produced by TRT when most of the transformation rules available for a language pair are used in TRT? r How to reliably identify native source language words? r Are word frequency lists mined from the Web competitive with the Web as a collection of documents as FITE-TRT's frequency source? r What are the translation recall and precision and indication precision (see the definitions below) of the proposed FITE-TRT method? r What is the contribution of each step in the FITE-TRT process to its overall effectiveness? r What is the effectiveness of a standard CLIR system boosted by the use of FITE-TRT in comparison to a CLIR system augmented with TRT and fuzzy matching OOV word methods, and in comparison to dictionary-translationonly CLIR and monolingual baselines? The effectiveness of FITE-TRT was evaluated by using the measures of translation recall, translation precision, and indication precision. For spelling variants translation recall is defined as the proportion of source words for which FITE identifies correct equivalents among all source words. For example, if there are 10 source words and TRT gives for these, 100 target language word forms, among which there are correct equivalents for 8 source words, then translation recall is 8/10 = 80%. Translation precision is defined as the proportion of correct equivalents among all words that are indicated as equivalents. For example, if FITE identifies 10 translation equivalents of which 9 are correct equivalents translation precision is 9/10 = 90%. For native words the question of what share of them is translated by TRT is an irrelevant question, and naturally recall is not measured for them. For native source words indication precision is defined as the proportion of words correctly indicated to be untranslatable by TRT. For example, if there are 5 native source words and FITE indicates that none of these translation equivalents are contained in the translation sets indication precision is 5/5 = 100%. Retrieval effectiveness was evaluated using the measures of mean average precision (MAP) and precision at 20 documents. MAP is a standard evaluation measure used in TREC (http://trec.nist.gov), and it refers to the average of the precision values obtained after each relevant document is retrieved. MAP is a system-oriented measure while precision at 20 documents is important from the practical IR standpoint. The probability of a searcher scanning further down a ranked result list decreases as (s)he scans down and we use
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

Frequency-Based Identification of Correct Translation Equivalents (FITE)

·

2:7

a document cutoff value of 20 as a rule of thumb for the stopping point of scan. 4. THE FITE TECHNIQUE 4.1 Frequency Data FITE identifies the correct translation equivalents among the TRT generated word forms by their frequency distribution in some corpus. Frequencies for FITE were taken from the Web and word frequency lists. In the case of the Web we consider document frequency (DF) and in the case of frequency lists word frequency (WF). DF statistics were collected using the Altavista search engine and its language selection feature. A research assistant fed the word forms into the search engine, which reported for each word form the number of documents containing the word form. The word frequency lists were mined from the Web using a Web mining technique, which is described next. In the first step of the Web mining process a query script based on the use of text-based Web browser Lynx was run to fetch medical and biological documents in a desired language from the Google search engine. The query script described in Zhang and Vines [2004] was modified for this purpose. We used the following parameters and parameter values in the script: language [=English/Finnish/German/Spanish]; the number of documents to fetch [=700]; query keys [the words medicine, biology, and disease (conjuncted by the AND-operator) and the corresponding words in Finnish, German, and Spanish]. The use of these keys directed the actual Web mining towards medical and biological sub-Webs. In the second step, URLs were extracted from the fetched documents and were saved in a file. In the third step, the URL file was cleaned by removing duplicates so that only URLs with unique domain names were kept in the file. The URL file served as an input for the fourth step, the actual Web mining stage where documents were downloaded from each Web site represented in the URL file using a wget program (http://www.gnu.org/software/wget/). Wget's parameter "directory depth" was set at 3--on each Web site documents at directory depths 1­3 were downloaded. In the fifth step of the process all downloaded documents were combined into one large file. In the sixth step, word frequency lists were constructed from the combined document file. The number of documents downloaded from the Web varied depending on the language. For example, for German 35 000 documents were downloaded. The total size of these documents was 2.26 GB. The numbers of unique words contained in the frequency lists are as follows: r r r r English: 762,000 words Finnish: 886,000 words German: 470,000 words Spanish: 386,000 words

We did the Web experiments prior to the word frequency experiments. Since the results of the Web experiments indicated that the contribution of the second
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

2:8

·

A. Pirkola et al.

intermediate language (French) was small it was not considered in the frequency list experiments, and we did not construct a word frequency list for French. Its minor contribution was probably due to the fact that it was used as the second intermediate language, rather than due to its linguistic features. In statistical MT the choice between translation alternatives depends on the translation probabilities of the alternatives and their context [Al-Onaizan et al. 1999; Brown et al. 1990]. Translation probabilities are computed on a basis of aligned corpora. In contrast to this, the source and target language corpora used by FITE are independent of each other. In statistical MT bigram and trigram language models are typically used to capture the context. FITE is based on a unigram language model: no context dependence of translations is assumed. 4.2 Frequency Pattern In order to avoid several long function definitions not precisely in the focus of our article, we introduce some notational conventions used in the definition of the FITE method. Notational Convention 1. Let SL be a source language and TL a target language, and sw be some source language word in the source language collection S. We denote this by sw  SL. We denote the word set produced by our TRT translation by TRT S L->T L (sw) using the transformation rules for SL- > TL translation. The result is a set: its elements tw hold the relationship tw  TRT S L->T L (sw). If the TRT translation is performed using a strict confidence factor (=10%) and a strict rule frequency (=10) (see Section 2), we denote this by TRT S L->T L|strict (sw). Notational Convention 2. Let sw be some word in source language SL: sw  SL. We denote its document frequency in the source language collection S by df S (sw). Note that if sw does not appear in any documents of S then df S (sw) = 0. If S is a source language wordlist containing word frequencies, we denote the frequency of sw in S by wf S (sw). Notational Convention 3. Let tw be some word of the target language TL in the target language document collection T : tw  TL. We denote its document frequency in T by dfT (tw). It refers to the frequency of target language documents that contain the word tw. Note that if tw does not appear in any documents of T then dfT (tw) = 0. If T is a target language wordlist containing word frequencies, we denote the frequency of tw in T by wfT (tw). Notational Convention 4. Let sw be some source language SL word: sw  SL, TL a target language, TWS = TRT S L->T L (sw) the word set produced by our TRT translation, and T a target language document collection or word list. The frequency-ranked list of words of TWS in T is denoted by R = trt-frank(TWS, T). Table II is an example of such a list with the frequency data added. For a given source language word sw we obtain this list by trt-frank(TRT S L->T L (sw), T ). The elements of this list are denoted by the usual notation, for example, trt-frank(TWS, T)[3] gives its third component. As an example, in the case of Table II, trt-frank(TRTSPA->ENG (biosintesis), EngWeb)[3] = biosyntesis. Its frequency is dfEngWeb (trt-frank(TRTSPA->ENG (biosintesis), EngWeb)[3]) = dfEngWeb (biosyntesis) = 634.
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

Frequency-Based Identification of Correct Translation Equivalents (FITE)
Table II. An Example of Generated Word Forms for R = trt-frank(TRT SPA->ENG (biosintesis), EngWeb) and their Document Frequencies df EngW eb (tw) in the English Sub-Web (Partial) Generated Word Form tw  R biosintesis biosintesis biosyntesis biosinthesis biosynthessis biosintessis biosinthessis biosyntessis df EngW eb (tw) 2 230 000 909 634 255 3 0 0 0

·

2:9

The core of FITE is that except for the translation equivalents the word forms yielded by TRT are malformed rather than real words, or they are rare words, for example, foreign language words in the target language text. The equivalents belong to a language's basic lexicon and are much more common in the language than the other word forms. This regular frequency pattern allows the identification of the equivalents. The example in Table II shows the document frequency pattern associated with the word forms obtained by TRT for the Spanish word biosintesis in Spanish-English TRT in the English sub-Web. The word forms are sorted by document frequency, by trt-frank(TRTSPA->ENG (biosintesis), EngWeb). We can see that the DF of biosynthesis, the equivalent of biosintesis, is remarkably higher than the DFs of the other the word forms. This type of frequency distribution is very common for word forms within a translation set of TRT. Given a target word form ranking R = trt-frank(TWS, T), the magnitude of difference between the document frequency of the first word form (dfT (R[1])) and the document frequency of the second word form (dfT (R[2])), or the frequencies between R[2] and R[3] (see Section 4.5) forms the basis of the equivalent identification. We used the coefficient value (the magnitude of difference) of 10 for the identification of equivalents (both for Web and word frequency lists). The same pattern holds for the Web and word frequency lists, with the main differences being in that in the case of frequency lists word frequencies instead of document frequencies are considered and in that Web gives more malformed words than the frequency lists. The following definition of the function freqpattern-ok checks whether the frequencies of two target language words twi and tw j have the required pattern. Definition 1. Let twi and tw j be two candidate word forms in the target language (sub-) Web document collection, or word frequency list, T as given by TRT. Let dfT (twi ) and dfT (tw j ) be their frequencies in T . Let  be a corpus dependent normalizing factor,  > 1. The Boolean function freq-pattern-ok gives the value true if the frequency of twi in T is at least  times the frequency of tw j in T . freq-pattern-ok(twi , tw j , , T ) = true, if dfT (twi )  ( × dfT (tw j ) false, otherwise.

ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

2:10

·

A. Pirkola et al.

Typically, the function freq-pattern-ok is applied on two consecutive words in a frequency-ranked order. For example, freq-pattern-ok(biosynthesis, biosintesis, 10, EngWeb) yields the value true (Table II). In the tests, the coefficient  was experimentally set at  = 10 using the training data (Section 5.1.1). 4.3 Relative Frequency There are situations where the highest DF (WF) is possessed by a word that is not the correct equivalent. For example, the source word may occur frequently in a target language collection; if TRT fails to translate the source word it may appear at the first position in a translation set. (A source word is always included in TRT's translation set because source and target language words may be identical.) Also, in the case of Web as a document collection there are mixed language pages some of which a search engine may consider target language pages, which wrongly increases the target DF of a source word found in the mixed language pages. TRT may also accidentally give high DF words that are not correct equivalents. As a solution for this problem, we compute relative document frequency (rel-df) and relative word frequency (rel-wf), defined as follows. Definition 2. Let sw be a source language word in the source language collection S, and tw a target language word form in the target language (sub-) Web document collection T as given by TRT. Let df S (sw) be the frequency of sw in S and dfT (tw) the frequency of the target language word tw in T . Let  be a corpus dependent normalizing factor,  > 0. The function rel-df gives the relative document frequency for tw in T. Definition 3. Let sw be a source language word in the source language word list S, and tw a target language word form in the target language word list T as given by TRT. Let wf S (sw) be the frequency of sw in S and wfT (tw) the frequency of the target language word tw in T . Let  be a corpus dependent normalizing factor,  > 0. The function rel-wf gives the relative word frequency for tw in T. rel-wf(tw, sw,, T, S) = wfT (tw)/(xwf S (sw)). The coefficient  is a corpus dependent normalizing factor. It is assigned such a value that rel-df and rel-wf > 1 indicate that the target word form is an equivalent, and rel-df and rel-wf < 1 indicate the equivalent is not found in the translation set. The coefficient values reflect the relative sizes of the sub-Webs/word frequency lists in relation to each other. In our case  = 2 was used in all test conditions. The value  = 2 was determined experimentally. The values of  from 1 to 2 are appropriate for the conditions where the target corpus is much larger than the source corpus, which was the case in our experiments. The Finnish word frequency list contains more words than the English list (Section 4.1). However, the sum frequency over all words is substantially higher in the English than Finnish list. This allows the use of  = 2 in the rel-wf formula also for Finnish-English. The example in Table III illustrates the case where the word with the highest DF is not the correct equivalent. The translation set contains the word forms and the associated frequencies of English Web pages for a Spanish source
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

Frequency-Based Identification of Correct Translation Equivalents (FITE)

·

2:11

Table III. Generated Word Forms and Their Frequencies for the Source Word fraccionamiento (Partial) Generated Word Form tw  R fraccionamiento fraccionamento fraccionament fraccionamient fraccionamente fraccionamyento fraccionamyent dfEngWeb (tw) 58 000 95 31 7 3 0 0 df SpaW eb (fraccionamiento) 416 000 416 000 -- -- -- -- -- rel-df 0.07 <0.01 -- -- -- -- --

Table IV. FITE's Length Criteria # characters in the source word 5 6 7­10 >10 Accepted # characters in the target work form 4­7 5­8 length difference 0­2 characters length difference 0­3 characters

word fraccionamiento. A typical frequency pattern is found. However, fraccionamiento, the word with the highest DF, is the Spanish source word not translated into English. Its DF in the Spanish portion of Web is 416 000. It is not accepted as an equivalent since rel-df(fraccionamiento, fraccionamiento, 2, EngWeb, SpaWeb) < 1. We considered the two highest ranked word forms, and naturally also for the second form, fraccionamento, rel-df < 1. 4.4 Length Factor Cross-lingual spelling variants are close to each other in word length. A great difference between the length of a target word form and the source word is an indication of a wrong equivalent. The length factor is taken into account, as FITE identifies equivalents. The length criteria for accepting an equivalent candidate as an equivalent are shown in Table IV. It can be seen, for example, that when a source word contains 7 characters the target word form has to have from 5 to 9 characters in order to be accepted as an equivalent. Definition 4. Let sw be a source language word and len(sw) its length in characters. Likewise, let tw be a target language word and len(tw) its length in characters. The Boolean function tw-len-ok gives the value true if the length of the target word tw is within the range defined in Table IV. tw-len-ok(tw, sw) = true, if 4  len(tw)  7 and len(sw) = 5 true, if 5  len(tw)  8 and len(sw) = 6 true, if |len(tw) - len(sw)|  2 and 7  len(sw)  10 true, if |len(tw) - len(sw)|  3 and len(sw) > 10 false, otherwise 4.5 The Application of FITE In the empirical experiments, the source test words (Section 5.1.1) were translated into English by the TRT translation program. The applied thresholds were
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

2:12

·

A. Pirkola et al.

described in Section 2. The equivalents were searched for from the translation sets using the FITE technique. As described in Sections 4.2­4.4, the main criteria of equivalent identification of FITE are the following: (1) the frequency patterns of the top word forms tested by the function freq-pattern-ok, (2) the relative frequency criterion tested by the rel-df/rel-wf functions, and (3) length criterion tested by the function tw-len-ok. The basic idea is to apply the criteria 1­3 in three steps A­C: First, in Step A, direct translation is tried and then in Steps B and C the pivot language translations one after the other. The criteria are first applied to the highest ranking target word candidate as given by the function trt-frank. If these steps do not yield a solution, then basically the same steps are repeated with the second highest ranking target word candidate. This process is specified as Algorithm find-equivalent, which is presented in the Appendix. The algorithm is for the case of word frequency lists S and T for the source and target languages. In the case of Web document collections, the word frequency lists are replaced by a function that gives the Web document frequency for a given source word. The TRT rule bases for the source, pivot and target languages, as described above, need to be available but are not precisely defined (see notational conventions in Section 4.2). We use the notations and functions of preceding sections in the definition of the algorithm. The algorithm find-equivalent first tries the first candidates produced by the TRT direct or pivoted processes. It calls the procedure direct-trans to produce the frequency-based ranking of the direct TRT candidates. The procedure generates them as the list R, and then the first component of R is tested for the criteria 1­3 by the procedure test-cand. If the first component passes the test it is given as the equivalent. If not, the algorithm find-equivalent then uses the first, and finally the second, pivot language translation, given by the procedure pivot-trans, which first checks the number of pivot language word forms obtained. The TRT rules are used liberally (the thresholds of CF = 4.0% and frequency = 2 are used; see Section 2), if there are at most 40 candidates and otherwise strictly (the thresholds of CF = 10.0% and frequency = 10 are used). Either way produces a target language word candidate list TWS, which then is ranked by frequency and the first component tested for the criteria 1­3. If the first pass, focusing on the first-ranked components, is not successful, then the algorithm find-equivalent tries the second equivalent candidate produced by the TRT processes. The first component is still selected as the equivalent if the three criteria are fulfilled as follows: the second component passes the frequency pattern and relative frequency criteria and the first one, the length criterion. The second word form is selected as the equivalent only if the first word form does not meet the length criterion and the second form meets all the three criteria. Otherwise the source word is indicated to be untranslatable by means of TRT--the string "nil" is returned. We found empirically the need to compare the second candidate word form to the third form to find out if there are more than one correct target language words (high frequency word forms) in the translation set. If there are exactly two acceptable words, the first word rather than the second, is selected as the equivalent based on our observations that in these cases the equivalent tends to be at the first position. The second
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

Frequency-Based Identification of Correct Translation Equivalents (FITE)

·

2:13

TRT Rule Production

TRT Rule Base

Frequency Statistics (Web Search)

Translation Recall Translation Precision

OOV Source Word

Identified Target Word

TRT Translation

Translation Candidates

FITE Identification Native Source Word

Indication Precision

Absolute Frequency Ok

Relative Frequency Ok

Length Difference Ok

Fig. 1. The FITE-TRT process.

word form is accepted as the equivalent only if the first form does not meet the length criterion. In the actual experiments described in Section 5, the algorithm findequivalent was applied/modified as follows. In the case of frequency lists the second pivot language (French) was not considered. Finnish-English experiments differed from the Spanish-English experiments in that there were two direct translation routes thanks to two Finnish-English rule collections. The order of the use of the translation routes for Finnish-English was as follows: Finnish-English/collection 1, Finnish-English/collection 2, Finnish-GermanEnglish, and Finnish-French-English. All the source words were in base form, and only base form equivalents were accepted as correct equivalents. Thus, equivalents in plural form and the derivatives of the actual equivalents were not accepted as correct equivalents. This is because our aim is to develop a dictionary-like rule-based translation method, which indicates the precise equivalents of source words. We conclude this section by summarizing, in Figure 1, the FITE-TRT process. The left side of the figure describes the production of transformation rules and the translation of OOV words by means of TRT. The FITE technique--the focus of the present article--is the grey shaded area. FITE-TRT effectiveness was evaluated using the measures of translation recall and precision and indication precision. 5. EXPERIMENTS AND FINDINGS In this section we present the methods and data used in the FITE-TRT and CLIR effectiveness experiments and the experimental results. Subsection 5.1
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

2:14

·

A. Pirkola et al.

presents the training and test words, describes how the words were translated by means of TRT, and presents the findings of the FITE-TRT effectiveness experiments. The CLIR experiments are dealt with in Subsection 5.2. 5.1 FITE-TRT Effectiveness 5.1.1 Training and Test Word Sets and Translation by TRT. FITE-TRT is intended to handle both spelling variants and native source language words. The training and test word sets contained both types of words. Next we describe the selection of training and test words. Then we characterize quantitatively the difference between cross-lingual spelling variants and native words. We used a training word set for the development of the FITE technique. The set contained the title words (n = 75) of the Spanish CLEF topics numbered 91 to 109. In addition to native Spanish words, the titles contain Spanish-English spelling variants, native English words, and English acronyms. The effectiveness of FITE-TRT was evaluated using four sets of test words. For each source language word set there was a corresponding English word set that contained the equivalents of the source words. For the first two test word sets a list of English biological and medical terms was gathered manually from the index of CLEF's [Peters 2005] LA Times collection. The English terms were translated into Spanish and Finnish by means of translation dictionaries and monolingual (Spanish and Finnish) medical dictionaries. From these words we selected Spanish-English and Finnish-English spelling variants for our tests. The identification of spelling variants was done based on the similarity of the Spanish-English and Finnish-English word pairs judged by a researcher. The similarity feature used as a selection criterion is discussed in Section 3 and later in this section. The Spanish terms formed the first, and the Finnish terms the second, test word set. Both contained the same terms (n = 89) albeit in different languages. These terms are called bio-terms. For the third and fourth test word sets, TREC Genomics Track 2004 topics in Spanish and Finnish (Section 5.2.1) were translated into English using the UTACLIR system, an automatic dictionary-based query translation and construction system developed in the Information Retrieval Laboratory at the University of Tampere [Hedlund et al. 2004]. The OOV keys of the UTACLIR runs were used as test words. Among the OOV keys there were, in addition to spelling variants, native Spanish/Finnish words as well as English words and English acronyms. The Spanish word set contained 98 and the Finnish set 53 OOV keys (after the removal of short words). The difference in the number of the OOV keys reflects the different sizes of UTACLIR's Spanish-English and Finnish-English dictionaries. These test key sets are here called OOV-UTACLIR-SPA-ENG and OOV-UTACLIR-FIN-ENG. Words containing four or less letters were not translated by TRT. This restriction was set because the short words were English acronyms and they need not be translated. (Generally, acronyms cannot be translated by means of TRT which only handles spelling variants.) On the other hand, cross-lingual spelling variants are not very short words. Within the four test word sets there were two
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

Frequency-Based Identification of Correct Translation Equivalents (FITE)
Table V. LCS/MWL for the Test Words Work type Spa-Eng spelling variants Bio terms OOV words Spanish native words Fin-Eng spelling variants Bio terms OOV words Finnish mative words # words 89 93 5 89 48 5 Average LCS/MWL 0.839 0.911 0.339 0.784 0.853 0.361

·

2:15

Standard Deviation 0.114 0.110 0.105 0.114 0.117 0.085

short (4-letter) spelling variants, which were removed from the sets according to the short word restriction. The total number of unique source words translated by TRT was 89 + 98 (Spanish) + 89 + 53 (Finnish) = 329 words. To characterize quantitatively the difference between cross-lingual spelling variants and native words, we computed for both types of source language test words their degree of similarity with respect to their English equivalents using a simple measure of longest common subsequence divided by the mean length of source and target words (LCS/MWL). LCS is defined as the length of the longest subsequence of characters shared by two words. The closer to 1.0 LCS/ MWL is, the more similar the words are. As an example, for the Spanish bioterm omnivoro LCS/MWL = 7/((8 + 8)/2) = 0.875 with respect to the English equivalent omnivore. For the native Spanish OOV word vinculante LCS/MWL = 0.353 with respect to the equivalent binding. Table V shows the results of LCS/MWL calculations. From the viewpoint of TRT, the target language (English) words as source words are similar cases as spelling variants and they were thus regarded as spelling variants in the sets OOV-UTACLIR-SPA-ENG and OOV-UTACLIR-FIN-ENG. (As mentioned in Section 4.3, a source word is included in TRT's translation set because source and target language words may be identical.) In cases where native Spanish and Finnish words had multiple meanings in English the meaning that appeared in the Genomics Track topic was selected for LCS/MWL calculation. Both the Spanish-English and Finnish-English OOV word sets contained five native words. It can be seen in Table V that for bio-terms and spelling variant OOV words, the average LCS/MWLs are 0.839 and 0.911 (Spanish-English) and 0.784 and 0.853 (Finnish-English). For native Spanish and Finnish words average LCS/MWLs are much lower: 0.339 for Spanish and 0.361 for Finnish. Low standard deviation figures show that the LCS/MWL values are clustered around the average values. In the experiments the source words were translated by the TRT program through direct and indirect translation routes into English using the confidence factor and rule frequency thresholds (Section 2). The equivalents of source words were identified from TRT's English translation sets by means of the FITE technique, as described in Section 4.5. Like target language translation sets, the intermediate translation sets are often large, and only five top German
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

2:16

·

A. Pirkola et al.

Table VI. FITE-TRT Effectiveness. Translation Recall and Translation Precision for bio-terms Source language/ Frequency corpus Spanish Bio terms/Web Bio terms/frequency lists Finnish Bio terms/Web Bio terms/frequency lists Translation Recall 81/89 73/89 64/89 60/89 Translation Recall % 91.0 82.0 71.9 67.4 Translation Precision 81/82 81/82 64/66 73/75 Translation Precision % 98.8 98.8 97.0 97.3

Table VII. FITE-TRT Effectiveness. The Contribution of Different Steps to Translation Recall for bio-terms Frequency corpus/ Translation route Web First direct route Second direct route First indirect route Second indirect route All Frequency lists First direct route Second direct route First indirect route All Spanish-English Recall 73/89 -- 6/89 2/89 81/89 (91.0%) 70/89 -- 3/89 73/89 (82.0%) Recall % 82.0 -- 06.7 02.2 90.9 78.7 -- 3.4 82.1 Finnish-English Recall 49/89 15/89 0/89 0/89 64/89 (71.9%) 45/89 15/89 0/89 60/89 (67.4%) Recall % 55.1 16.9 00.0 00.0 72.0 50.6 16.9 0.0 67.5

and French forms in a frequency-ranked translation set were further translated into English. Different English translation sets corresponding to the same Finnish/Spanish source word were combined. 5.1.2 Findings. Table VI reports the translation recall and precision results for bio-terms, and Table VII the contribution of different translation routes to the recall for bio-terms. Table VIII presents the translation recall and precision, and indication precision results for OOV-UTACLIR-SPA-ENG and OOVUTACLIR-FIN-ENG words. Table VI shows that Spanish-English FITE-TRT reaches 91.0% recall in the case of Web document frequencies and 82.0% recall in the case of word frequency lists. Finnish-English FITE-TRT reaches 71.9% (Web) and 67.4% (frequency lists) recall. While Spanish-English FITE-TRT achieves higher recall, precision is approximately the same and it is remarkably high for both language pairs: 97.0%­98.8%. The same trends hold for the OOV words (Table VIII): for Spanish-English recall is higher than for Finnish-English, and for both language pairs precision is very high (95.0%­97.6%). Table VII shows that the contribution of direct translation to the recall is substantial for both language pairs. For Finnish-English FITE-TRT, the contribution of the second direct route (collection 2) to the recall is high. Indirect translation adds recall only for Spanish-English. In the case of Web as a frequency corpus the first pivot language adds recall by 6.7% while the second one adds recall only by 2.2%.
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

Frequency-Based Identification of Correct Translation Equivalents (FITE)

·

2:17

Table VIII. FITE-TRT Effectiveness. Translation Recall and Translation/Indication Precision for OOV-UTACLIR-SPA-ENG and OOV-UTACLIR-FIN-ENG keys Source language/Frequency Translation Translation corpus/Word type Recall Recall % Spanish (OOV-UTACLIR-SPA-ENG) Web Spelling variants 83/93 89.2 Native words -- -- Frequency lists Spelling variants 81/93 87.1 Native words -- -- Finnish (OOV-UTACLIR-FIN-ENG) Web Spelling variants 35/48 72.9 Native words -- -- Frequency lists Spelling variants 38/48 79.2 Native words -- -- Translation/ Translation/ Indication Indication Precision Precision % 83/85 5/5 81/83 5/5 35/36 5/5 38/40 5/5 97.6 100.0 97.6 100.0 97.2 100.0 95.0 100.0

For the native words indication precision is 100% in all test situations (Table VIII). There were only 10 native Spanish and Finnish words in all, however the results are reasonable since the cases where TRT accidentally gives correct words are not common. 5.2 CLIR Effectiveness 5.2.1 Methods and Data. FITE-TRT was applied as part of an actual CLIR system. As test data we used TREC Genomics Track 2004 data [Hersh et al. 2005]. The data consisted of 50 test topics, a subset of the Medline collection containing around 4.5 million documents, and relevance judgments. Queries were formulated on the basis of the Title and Need fields of the topics. The data are well suited for investigating FITE-TRT since the topics are rich in technical (mainly biological and medical) terms. The topics were translated manually into Spanish and Finnish by a researcher. The final Spanish topics were formulated by a knowledgeable Spanish speaker (a university teacher of Spanish). The researcher is a native Finnish speaker and has expertise in medical informatics. The test system was the InQuery retrieval system [Allan et al. 2000; Larkey and Connell 2005]. InQuery is a probabilistic retrieval system based on the Bayesian inference network model. Queries can be presented as a bag of word queries, or they can be structured using a variety of query operators. In this study the translated queries were structured using InQuery's #syn-operator as described in Pirkola [1998] and Sperer and Oard [2000]. The keys within the #syn-operator are treated as instances of one key. The Spanish and Finnish topics were translated back into English using the UTACLIR system and the queries were then run on the Genomics Track test collection. UTACLIR's output without any OOV word technique provides crosslingual baseline for the FITE-TRT queries for which UTACLIR's OOV words were translated by means of TRT and equivalents were identified using FITE. The original English queries were also run to show the performance level of the
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

2:18

·

A. Pirkola et al.

translated queries. We also compared the effectiveness of FITE-TRT queries to the effectiveness of plain TRT and skipgram queries. Plain TRT is the TRT part of FITE-TRT, and for plain TRT queries UTACLIR's OOV words were translated by TRT with CF = 4% and frequency = 2. All translations of a source word were included in a query and were wrapped in the #syn-operator. In skipgram queries the OOV words were translated using a skipgram fuzzy matching technique [Keskustalo et al. 2003]. This string matching technique is a generalization of the n-gram technique where words are split into digrams on the basis of both consecutive as well as nonconsecutive characters (see below). In these comparison experiments only direct translation/matching was examined since it is not sensible to study indirect fuzzy matching. Also, indirect TRT without frequency-based selection of intermediate word forms for further translation, would give very long queries that would be hard to manage. The skipgram fuzzy matching technique constructs digrams of both consecutive and nonconsecutive characters of words [Keskustalo et al. 2003]. The generated digrams are put into comparable categories based on the number of skipped characters as digrams are constructed. The character combination index (CCI) indicates the number of skipped characters as well as the comparable categories. Here we used CCI = ([0], [1, 2]). This means that digrams formed of consecutive characters form one comparable category, and digrams with one and two skipped characters, the other. CCI = ([0], [1, 2]) was very effective in the study conducted by Keskustalo et al. [2003] who explored the same general problem as we do in this article: the identification of translation equivalents of cross-lingual spelling variants. Skipgrams with CCI = ([0], [1, 2]) outperformed conventional digrams formed of consecutive characters of words. In the skipgram experiments each OOV word was matched against each string in the index of the TREC collection. Two types of queries were constructed: for each OOV word (1) two best matches and (2) five best matches were selected for a query. In the query the best matches were linked to each other with InQuery's #syn-operator. All inflected query words were rendered into base form for a dictionary lookup. For Finnish, UTACLIR's morphological analyzer gave base forms for most inflected words, and those that the analyzer was not able to handle were lemmatized manually. All Spanish inflected words were lemmatized manually. Manual lemmatization of the inflected keys was necessary because at this stage of development TRT only translates lemmas. Thus, the results show CLIR performance when a searcher gives query keys in base form. The results were tested for significance by the Wilcoxon signed rank test [Conover 1980]. The Wilcoxon test takes into account both the direction and magnitude of change between each comparable result of a query. In summary, we run the following queries in Spanish-English and FinnishEnglish CLIR experiments: r Original English queries r UTACLIR baseline (with OOV words passed through unchanged) r UTACLIR + FITE-TRT (Web) r UTACLIR + FITE-TRT (frequency lists)
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

Frequency-Based Identification of Correct Translation Equivalents (FITE)

·

2:19

Table IX. Spanish-English CLIR Performance. Indirect Translation is Involved ( Statistical Significance Level 0.001) Query type Baselines English queries Utaclir baseline FITE-TRT queries Web Frequency lists MAP 0.3195 0.2018 0.2832 0.2728 % change wrt Utaclir -- -- +40.3 +35.2 Pr. at 20 docs 0.5152 0.3009 0.4530 0.4490 % change wrt Utaclir -- -- +50.5 +49.2

Table X. Finnish-English CLIR Performance. Indirect Translation is Involved ( Statistical Significance Level 0.001) Query type Baselines English queries Utaclir baseline FITE-TRT queries Web Frequency lists MAP 0.3195 0.1971 0.2491 0.2480 % change wrt Utaclir -- -- +26.4 +25.8 Pr. at 20 docs 0.5152 0.3047 0.4420 0.4460 % change wrt Utaclir -- -- +45.1 +46.4

Table XI. The Performance of FITE-TRT, TRT, and Skipgram Queries. Indirect Translation is not Involved. ( Statistical Significance Level 0.05) Spanish-English FITE-TRT/Web TRT FITE-TRT/Frequency lists skipgram/5 best matches skipgram/2 best matches MAP 0.2814 0.2796 0.2691 0.2611 0.2473 Finnish-English FITE-TRT/Web FITE-TRT/Frequency lists skipgram/5 best matches skipgram/2 best matches TRT MAP 0.2447 0.2436 0.2411 0.2395 0.2393

r UTACLIR + TRT r UTACLIR + skipgrams with two best matches r UTACLIR + skipgrams with five best matches 5.2.2 Findings. The results of the retrieval experiments are presented in Tables IX­XI. The statistical significance of the test queries was tested against the UTACLIR baseline (Tables IX, X) and against UTACLIR + FITE-TRT/Web (Table XI). In the tables the statistical significance is indicated by asterisks. As expected, the queries where OOV keys are translated by FITE-TRT perform better than the baseline queries where OOV keys are retained untranslatable (Tables IX and X). In Spanish-English CLIR, MAP improvement percentages are 40.3% (Web) and 35.2% (frequency lists). Precision at 20 documents is improved by 50.5% (Web) and 49.2% (frequency lists). Also FinnishEnglish FITE-TRT queries remarkably outperform the CLIR baseline although performance improvements are smaller than in the case of Spanish-English (Table X). All Spanish-English and Finnish-English results are statistically significant at p = 0.001. These findings are in agreement with the high number of OOV keys in the UTACLIR runs and FITE-TRT's high translation recall and precision. It should be noted that some OOV words may only be marginally
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

2:20

·

A. Pirkola et al.

topical, in which case correct FITE-TRT identification may result in a performance drop. Therefore FITE-TRT performance does not always correlate linearly with CLIR+ FITE-TRT performance. Spanish-English FITE-TRT queries perform better than Finnish-English FITE-TRT queries, which were much longer and more ambiguous than SpanishEnglish queries due to the larger coverage of UTACLIR's Finnish-English dictionary. The higher degree of translation ambiguity and FITE-TRT's lower performance resulted in lower CLIR performance. The higher performance of English queries with respect to the performance of Spanish-English and in particular Finnish-English queries is mostly caused by translation ambiguity. Table XI shows the performance of FITE-TRT, TRT, and skipgram queries. The results are ranked based on MAP values. It can be seen that for both language pairs the best OOV word method is FITE-TRT with Web document frequencies. However, it shows significantly better results only against the cases of Spanish-English/skipgram/2 and Finnish-English/TRT, and the results are significant only at p = 0.05. In the latter case, the difference in MAP is small (0.2447­0.2393) but systematic, and hence significant. In comparison to UTACLIR baselines (Tables IX and X) all queries perform well. It was expected that plain TRT queries yield good results since TRT with CF = 4% and frequency = 2 very often gives a source word's correct equivalent while the other translations typically are malformed word forms not occurring in the database index and having no effects whatsoever on retrieval results. In many applications (outside cross-language document retrieval) it is, however, important to avoid the ambiguity of TRT and obtain one reliable translation, as given by FITE-TRT. 6. DISCUSSION AND CONCLUSIONS In this study we first examined the following two basic questions. Regarding spelling variants, how to effectively identify the correct equivalent of a source word among the many word forms produced by TRT when most of the transformation rules available for a language pair are used in TRT. How to reliably identify native source language words: source words that cannot be correctly translated by TRT. We devised the FITE-TRT technique--a novel OOV word translation technique. Its effectiveness was tested for Spanish-English and Finnish-English spelling variants and actual OOV words in the domains of biology and medicine. Here the research questions were as follows. What are the translation recall and precision and indication precision of the proposed FITE-TRT method? Are word frequency lists mined from the Web competitive with the Web as a collection of documents, as FITE-TRT's frequency source? What is the contribution of each step (direct and indirect translation routes) in the FITE-TRT process to its overall effectiveness? We found that depending on the source language and frequency source, FITETRT may achieve high translation recall. When equivalents were identified on the basis of Web document frequencies Spanish-English FITE-TRT achieved 89.2%­91.0% recall. For Finnish-English and for frequency lists mined from the Web, recall was lower but still substantial. The lowest recall (67.4%) was
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

Frequency-Based Identification of Correct Translation Equivalents (FITE)

·

2:21

obtained for Finnish-English/frequency lists. The results indicated that FITETRT achieves high precision. FITE indicates precisely the equivalents of source words as well as the native words. For Spanish-English and Finnish-English test words translation precision was 95.0%­98.8%. All native OOV words were correctly indicated to be untranslatable by TRT. The test requests only contained 10 native OOV words: the results reported here need to be corroborated using a larger set of native words. The contribution of direct translation to the overall recall was substantial for Spanish-English bio-terms. Direct translation achieved 82.0% recall while the overall recall was 91.0%. We expected that Finnish-English FITE-TRT through pivot languages would have compensated failures of direct translation but that did not happen. Indirect translation did not help at all. These findings suggest that that the costs of indirect translation against its benefits are high. Because a pivot language increases FITE-TRT complexity it does not seem sensible to use two pivot languages as part of a FITE-TRT system. Last, we examined the effectiveness of a standard CLIR system boosted by the use of FITE-TRT in comparison to a CLIR system augmented with TRT and fuzzy matching OOV word methods, and in comparison to dictionarytranslation-only CLIR and monolingual baselines. It was shown that FITETRT with Web document frequencies was the best technique among several approaches to handling OOV words tested in the experiments. Dictionarybased CLIR augmented with FITE-TRT performed substantially better than the baseline, where OOV keys were kept intact. In Spanish-English CLIR MAP improvement percentages were 40.3% (Web) and 35.2% (frequency lists). Also Finnish-English FITE-TRT queries remarkably outperformed the CLIR baseline although performance improvements were smaller than in the case of Spanish-English (about 26% for both Web and frequency lists). The TRT program we used in this study was not able to process a high number of word forms in a reasonable time frame, and we had to apply CF and frequency thresholds. In the preliminary tests we translated without using any thresholds, and for long words we had to end the program because it was not able to complete the translation process within a day. We observed that for many source words, equivalents were not found in translation sets because the CFs and/or frequencies of the relevant rules were below the thresholds. We therefore expect that recall values can still be improved by using a more sophisticated TRT program that allows efficient TRT even without the use of thresholds. For example, in the case of Spanish/bio-terms/Web there were 81 correct identifications, one wrong identification, and seven words for which TRT did not identify equivalents. For five of the seven words, equivalents were not contained in the translation sets because of low CF or frequency rules. The five words and the rules are shown in Table XII. Also deficiencies in the Finnish-English rule collections and word frequency lists caused recall errors. FITE-TRT effectiveness was better for SpanishEnglish than Finnish-English. The better effectiveness can be attributed to the higher quality of Spanish-English rule collection. Deficiencies in the FinnishEnglish transformation rules can be overcome by using more data in rule generation. The frequency lists we constructed using Web mining turned out to be
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

2:22

·

A. Pirkola et al.
Table XII. Low CF/Frequency Rules in the Test Situation of Spanish-English/Bio-terms/Web Spanish word bromo alucinogeno seudoefedrina espinaca estricnina English equivalent bromine hallucinogen pseudoephedrine spinach strychnine Rule mo mine e 1 195 0.51 a ha b 4 1891 0.21 s ps b 13 907 1.43 ca ch e 3 832 0.36 ric ryc m 1 284 0.35

good frequency data for FITE. However, for some source word/equivalent pairs, frequencies were too low for rel-wf formula, which resulted in a decrease in recall performance. This deficiency can be overcome by adding more data to the existing lists. The main advantage of using frequency lists is that after the lists have been constructed FITE-TRT is independent of the Web. This is important when a practical FITE-TRT implementation is developed. The frequency lists we used contain biological and medical terms in accordance with the test terminology used in the study. The lists are large and contain terms in various domains. The application of FITE-TRT in the other domains may require lists with different types of terms. However, for each domain, the lists are concise enough to be held in main memory for efficient implementation. Overall the percentage of wrong equivalents indicated by FITE was small. The identification of derivatives and plural forms of the correct equivalents was the primary cause of precision errors. As an example, for the Finnish word leukosyytti and the Spanish word bacteria the correct equivalents are leucocyte and bacterium while FITE gave the words leucocytic and bacteria. Many of these types of cases could be solved by augmenting the transformation rules with word class information, for example, that a rule is likely to refer an adjective rather than a noun. Information on OOV word's word class is achieved when the sentential context of the OOV word is known. At present TRT is only intended to translate singular base forms. Word class information is needed if FITE-TRT will be applied to running texts containing inflectional word forms. This would imply the supplementation of rule collections with word class information. The next main challenge in the FITE-TRT research is to improve the rules such that FITE-TRT can handle words in a running text. The CLIR experiments showed that the best fuzzy translation/matchingbased query was FITE-TRT with Web document frequencies. The FITE component of FITE-TRT was the focus of this article, and here an important issue is its contribution in CLIR. The results showed that in the case of Finnish-English, FITE-TRT was significantly better than plain TRT but only at p = 0.05. In the case of Spanish-English, FITE-TRT did not show significantly better results. Overall, the results are inconclusive, and the issue needs to be investigated more thoroughly in future research. Such factors as query structure and other than OOV keys affect the effectiveness of FITE-TRT and TRT queries. Also, efficiency needs to be taken into account in future research. TRT queries are much longer than FITE-TRT queries and thus require more processing power.
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

Frequency-Based Identification of Correct Translation Equivalents (FITE)

·

2:23

On the other hand, the FITE component of FITE-TRT increases computational expense. In other information systems than retrieval systems, in particular in MT fuzzy translation, TRT does not come into question. The good quality of translations achieved through FITE-TRT suggests that it can contribute to better MT performance. There is still one CLIR-related application of FITE-TRT that is worth mentioning: an automatic construction of multilingual dictionaries of technical terms and proper names by means of FITE-TRT. The dictionary construction process could be designed to be largely automatic thanks to FITE-TRT's high degree of effectiveness. Given a list of words and a set of transformation rule collections the process would automatically yield the translation equivalents of the words in different languages--the result would essentially be a multilingual dictionary. The construction of dictionaries is a non-time-critical task; given enough time it would be possible to construct large multilingual dictionaries. The cost benefits of an automatic method are obvious. It can easily be seen that there is a difference in the cost of automatic as opposed to manual construction of a dictionary of, say, 10 languages and 50 000 dictionary entries.

APPENDIX FITE identification of the target language equivalent for a source language word by the algorithm find-equivalent:
input array S = {<w1 , f1 >, . . . , <wn , fn >} array T = {<v1 , g1 >, . . . , <vm , gm >} rulebase SL- > TL rulebase SL- > PL rulebase SL- > QL rulebase PL- > TL rulebase QL- > TL integer ,  output string equivalent procedure find-equivalent(sw): String i  1; A: equivalent  direct-trans(sw, i, SL, TL); if equivalent = nil then XL  PL; equivalent  pivot-trans(sw, i, SL, XL, TL); if equivalent = nil then XL  QL; equivalent  pivot-trans(sw, i, SL, XL, TL); if equivalent = nil and i = 1 then i  2; goto A else output equivalent. /* the source language SL word frequency list /*--see Section 4.1 /* the target language TL word frequency list /* the source-target TRT rule base--Section 2 /* the 1st source-pivot TRT rule base /* the 2nd source-pivot TRT rule base /* the 1st pivot-target TRT rule base /* the 2nd pivot-target TRT rule base /* the corpus coefficients--Sections 4.2­4.3 /* the TL equivalent or nil /* finds the equivalent for the source /* language word sw /* try the candidate word position 1 in R /* Step A: direct translation at ith position /* not found /* Step B: pivot language is PL /* try first pivot translation /* not found /* Step C: pivot language is QL /* try 2nd pivot translation /* still not found for the 1st position /* try the candidate word position 2 in R /* go through steps A­C /* output the translation or "nil"

ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

2:24

·

A. Pirkola et al.
/* test criteria 1­3 of tw1 against tw2 and sw /* criterion 1 : Definition 1 /* criterion 2 : Definitions 2­3 /* criterion 3 : Definition 4

procedure test-cand(tw1, tw2, sw, tw): Boolean if freq-pattern-ok(tw1, tw2, , T ) and rel-df(tw1, sw, ,T, S) > 1 and tw-len-ok(tw, sw) then true else false. procedure direct-trans(sw, i, SL, TL): String R  trt-frank(TRT S L->T L (sw), T ) if test-cand(R[i], R[i + 1], sw,R[1]) then equivalent  R[1] else if test-cand(R[i], R[i + 1], sw,R[i]) then equivalent  R[i] else equivalent  nil. procedure pivot-trans(sw, i, SL, XL, TL): String if |TRT S L->X L (sw)|  40 then PWS  TRT S L->X L (sw); TWS   pwP W S TRT X L->T L (pw); else PWS  TRT S L->X L|strict (sw); TWS   pwP W S TRT X L->T L|strict (pw); R  trt-frank(TWS, T) if test-cand(R[i], R[i + 1], sw,R[1]) then equivalent  R[1] else if test-cand(R[i], R[i + 1], sw,R[i]) then equivalent  R[i] else equivalent  nil.

/* translate directly into TL /* generate frequency ranked TL candidates /* test criteria 1­3 for the ith candidate in R /* the equivalent was found--the 1st component /* test criteria 1­3 for the ith candidate in R /* the equivalent was found--the 2nd component /* the equivalent was not satisfactory /* translate via pivot language /* check if too many candidates generated /* produce pivot language candidate set for sw /* produce TL candidate set for strings in PWS /* produce strict pivot language candidate /* set for sw /* produce strict TL candidate set for /* strings in PWS /* produce ranked TL translations for /* candidates in TWS /* test criteria 1­3 for the ith candidate in R /* the equivalent was found--the 1st component /* test criteria 1­3 for the ith candidate in R /* the equivalent was found--the 2nd component /* the equivalent is "nil"

ACKNOWLEDGMENTS

The Multilingual Medical Technical Dictionary (http://members.interfold.com/ translator) was provided by Andre Fairchild, of Denver, Colorado. We would like to thank her for permission to use the dictionary. GlobalDix Dictionary Software provided by Kielikone, plc. was used as part of the UTACLIR system. The InQuery search engine was provided by the Center for Intelligent Information Retrieval at the University of Massachusetts.
REFERENCES AL-ONAIZAN, Y., CURIN, J., JAHR, M., KNIGHT, K., LAFFERTY, J., MELAMED, D., OCH, F.J., PURDY, D., SMITH, N.A., AND YAROWSKY, D. 1999. Statistical machine translation: Final report. Johns Hopkins University 1999 Summer Workshop on Language Engineering. ALLAN, J., CONNELL, M.E., CROFT, W.B., FENG, F-F., FISHER, D., AND LI, X. 2000. Inquery and TREC-9. In Proceedings of the Ninth Text REtrieval Conference (TREC-9). Gaithersburg, MD. http://trec.nist.gov/pubs/trec9/t9 proceedings.html BALLESTEROS, L.A. 2000. Cross-language retrieval via transitive translation. In Advances in Information Retrieval: Recent Research from the CIIR. Kluwer Academic Publishers, 203­ 234. BROWN, P., COCKE, J., DELLA PIETRA, S., DELLA PIETRA, V., JELINEK, F., LAFFERTY, J., MERCER, R., AND ROOSIN, P. 1990. A statistical approach to machine translation. Comp. Ling. 16, 79­85. CHENG, P-J., TENG, J-W., CHEN, R-C., WANG, J-H., LU, W-H., AND CHIEN, L-F. 2004. Translating unknown queries with Web corpora for cross-language information retrieval. In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. Sheffield, UK, 146­153. CONOVER, W.J. 1980. Practical Nonparametric Statistics. John Wiley & Sons.
ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.

Frequency-Based Identification of Correct Translation Equivalents (FITE)

·

2:25

FUJII, A., AND ISHIKAWA, T. 2001. Japanese/English cross-language information retrieval: Exploration of query translation and transliteration. Comput. Humanit. 35(4), 389­420. GOLLINS, T., AND SANDERSON, M. 2001. Improving cross language retrieval with triangulated translation. In Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. New Orleans, Louisiana, 90­95. A HEDLUND, T., AIRIO, E., KESKUSTALO, H., LEHTOKANGAS, R., PIRKOLA, A., AND J¨ RVELIN, K. 2004. Dictionary-based cross-language information retrieval: Learning experiences from CLEF 20002002. Inf. Ret. 7, 99­119. HERSH, W.R., BHUPTIRAJU, R.T., ROSS, L., JOHNSON, P., AND KRAEMER, D.F. 2005. TREC 2004 genomics track overview. In Proceedings of the Thirteenth TExt REtrieval Conference (TREC-13). Gaithersburg, MD. http://trec.nist.gov/pubs/trec13/t13 proceedings.html KESKUSTALO, H., PIRKOLA, A., VISALA, K., LEPP¨ NEN, E., AND J¨ RVELIN, K. 2003. Non-adjacent diA A grams improve matching of cross-lingual spelling variants. In Proceedings of the10th International Symposium on String Processing and Information Retrieval (SPIRE 2003). Manaus, Brazil, 252­265. LARKEY, L.S., AND CONNELL, M.E. 2005. Structured queries, language modeling, and relevance modeling in cross-language information retrieval. Inf. Proc. Manage. 41(3) 457­473. A LEHTOKANGAS, R., AIRIO, E., AND J¨ RVELIN, K. 2004. Transitive dictionary translation challenges direct dictionary translation in CLIR. Inf. Proc. Manage. 40(6) 973­988. MENG, H., CHEN, B., GRAMS, E., KHUDANPUR, S., LO, W-K., LEVOW, G-A., OARD, D., SCHONE, P., TANG, K., WANG, H-M., AND WANG, J. 2000. Mandarin English Information (MEI): Investigating translingual speech retrieval. John Hopkins University Summer Workshop 2000. PETERS, C. 2005. CLEF--Cross-Language Evaluation Forum. http://clef.isti.cnr.it/ PIRKOLA, A. 1998. The effects of query structure and dictionary setups in dictionary-based crosslanguage information retrieval. In Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. Melbourne, Australia, 55­ 63. PIRKOLA, A., TOIVONEN, J., KESKUSTALO, H., VISALA, K., AND J¨ RVELIN, K. 2003. Fuzzy translation A of cross-lingual spelling variants. In Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. Toronto, Canada, 345­352. A PIRKOLA, A., TOIVONEN, J., KESKUSTALO, H., AND J¨ RVELIN, K. 2006. FITE-TRT: A high quality translation technique for OOV words. In Proceedings of the 21st Annual ACM Symposium on Applied Computing. Dijon, France, April 23­27. SPERER, R., AND OARD, D. 2000. Structured translation for cross-language IR. In Proceedings of the 23rd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. Athens, Greece, 120­127. TOIVONEN, J., PIRKOLA, A., KESKUSTALO, H., VISALA, K., AND J¨ RVELIN, K. 2005. Translating crossA lingual spelling variants using transformation rules. Inf. Proc. Manage. 41(4) 859­872. ZHANG, Y., AND VINES, P. 2004. Using the Web for automated translation extraction in crosslanguage information retrieval. In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval. Sheffield, UK, 162­169.
Received December 2005; revised March 2006, April 2007; accepted April 2007

ACM Transactions on Information Systems, Vol. 26, No. 1, Article 2, Publication date: November 2007.
